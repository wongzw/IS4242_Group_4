{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Import the necessary libraries"
      ],
      "metadata": {
        "id": "NdEWwQeGto2n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRtfA2NgAIb7"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D , Conv1D, MaxPool1D, MaxPool2D , Flatten , Dropout , BatchNormalization\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report,confusion_matrix, roc_auc_score, accuracy_score\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "import joblib\n",
        "import os\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPool2D, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization, Dropout, Dense, Flatten, Input, Lambda\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import ReduceLROnPlateau , EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam \n",
        "from tensorflow.keras import regularizers\n",
        "import tensorflow as tf\n",
        "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
        "from sklearn.metrics import roc_auc_score,f1_score\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-RSJh0JlKB_",
        "outputId": "ff7d5ce1-5853-4dd7-88d7-187d8f26bd57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xanvjXIQFK8t"
      },
      "outputs": [],
      "source": [
        "# Use the albumentations library for augmentation pipeline\n",
        "import albumentations as A\n",
        "\n",
        "transform = A.Compose([\n",
        "    # Randomly adjust the brightness of the image\n",
        "    A.RandomBrightnessContrast(),\n",
        "\n",
        "    # Randomly apply scaling, translation and shearing\n",
        "    A.Affine(scale=[0.8,1.2],translate_percent=0.05, shear=0.2, keep_ratio=True, p=0.5),\n",
        "\n",
        "    # Randomly apply rotation\n",
        "    A.Rotate(limit=10)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEy377YyPMuY"
      },
      "source": [
        "## Without MediaPipe\n",
        "This section contains the model without applying MediaPipe's hand landmark detection algorithm.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccFPmDRlPGWn"
      },
      "source": [
        "#### Read image and convert it to 28x28 matrix:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nGhlM2Tt0xmY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93d2d659-d269-4987-eea1-c24990b25a21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1221/1221 [02:55<00:00,  6.94it/s]\n"
          ]
        }
      ],
      "source": [
        "# Define directory path and initialize empty lists\n",
        "folder_name = '/content/drive/MyDrive/IS4242/data' \n",
        "path = folder_name\n",
        "img_list = []\n",
        "label_list = []\n",
        "txt = 'abcdefghiklmnopqrstuvwxy'\n",
        "\n",
        "# Iterate through files listed in the directory\n",
        "for i in tqdm(range(len(os.listdir(path)))):\n",
        "  filename = os.listdir(path)[i]\n",
        "\n",
        "  # If filename is of  type .jpg or .png, split the filename and take the first strings before a '-' or '_'\n",
        "  if filename.endswith(('.jpg','.png')):\n",
        "      label_name = re.split(r'[-_]', filename)[0].lower()\n",
        "      if label_name not in txt:\n",
        "        continue\n",
        "      \n",
        "      # Append the splitted filenames as labels\n",
        "      label_list.append(label_name)\n",
        "\n",
        "      # Open, resize image into 28 x 28 pixels and convert into greyscale then into np.array\n",
        "      img = Image.open(os.path.join(path, filename))\n",
        "      img = img.resize((28, 28), Image.ANTIALIAS)\n",
        "      img = img.convert('L')\n",
        "      img_array = np.array(img)\n",
        "      img_list.append(img_array)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnhcjdxaX5pb"
      },
      "outputs": [],
      "source": [
        "# Convert img_list into np.array and store as X \n",
        "X = np.array(img_list)\n",
        "\n",
        "# Convert y data into np.array and use one-hot encoding to store the labels\n",
        "y = np.array(label_list)\n",
        "y = np.array(list(map(lambda x:txt.find(x), y)))\n",
        "y = to_categorical(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qe39EoIxPSUr"
      },
      "source": [
        "#### Train test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3TP5kyryXAEE"
      },
      "outputs": [],
      "source": [
        "# Save X and y data as pickle\n",
        "output_dir = '/content/drive/MyDrive/IS4242/dump/'\n",
        "joblib.dump(X, output_dir+'X.pkl')\n",
        "joblib.dump(y, output_dir+'y.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load X and y pickle data\n",
        "output_dir = '/content/drive/MyDrive/IS4242/dump/'\n",
        "X = joblib.load(output_dir+'X.pkl')\n",
        "y = joblib.load(output_dir+'y.pkl')"
      ],
      "metadata": {
        "id": "uQxULlzrYTcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "heWd0I4TYpJl",
        "outputId": "20be643f-ec8d-4263-d37e-822ee588218b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(634, 28, 28)\n",
            "(159, 28, 28)\n",
            "(634, 24)\n",
            "(159, 24)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qc6PtL6oPUnt"
      },
      "source": [
        "#### Augmentation only on train data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Mx2XuirTNKf",
        "outputId": "2035b8b7-d2b4-4b5a-ad74-e57e7ff2b573"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/IS4242/dump/augmented_y.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "# Initialize augmented datalist\n",
        "augmented_X = []\n",
        "augmented_y = []\n",
        "\n",
        "# Loop through the train data set\n",
        "for i in range(len(X_train)):\n",
        "  # Perform augmentation and transformation 5 times for each data point\n",
        "  for j in (range(5)):\n",
        "      transformed = transform(image=X_train[i])\n",
        "      augmented_X.append(transformed['image'])\n",
        "      augmented_y.append(y_train[i])\n",
        "\n",
        "augmented_X = np.array(augmented_X)\n",
        "augmented_y = np.array(augmented_y)\n",
        "\n",
        "# Concatenate original set with augmentation set\n",
        "X_train = np.concatenate([X_train,augmented_X])\n",
        "y_train = np.concatenate([y_train,augmented_y])\n",
        "\n",
        "# Save augmented data as pickle file\n",
        "output_dir = '/content/drive/MyDrive/IS4242/dump/'\n",
        "joblib.dump(augmented_X, output_dir+'augmented_X.pkl')\n",
        "joblib.dump(augmented_y, output_dir+'augmented_y.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load augmented data\n",
        "output_dir = '/content/drive/MyDrive/IS4242/dump/'\n",
        "augmented_X = joblib.load(output_dir+'augmented_X.pkl')\n",
        "augmented_y = joblib.load(output_dir+'augmented_y.pkl')\n",
        "X_train = np.concatenate([X_train,augmented_X])\n",
        "y_train = np.concatenate([y_train,augmented_y])"
      ],
      "metadata": {
        "id": "XhezWeGjgZfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4hLE3l4WzYv",
        "outputId": "55253aa5-cbe9-43ae-a418-a10a12e7e099"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6974, 28, 28)\n",
            "(6974, 24)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfWb8w7hPX84"
      },
      "source": [
        "#### Reshape and divide the pixels by 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wiwpcpoi2tA1"
      },
      "outputs": [],
      "source": [
        "X_train = X_train/255.0\n",
        "X_test = X_test/255.0\n",
        "X_train = X_train.reshape(-1, 28, 28, 1)\n",
        "X_test = X_test.reshape(-1, 28, 28, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fk-szWv2k__",
        "outputId": "c2801588-10c6-4c19-f77a-e275502450fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6974, 28, 28, 1)\n",
            "(159, 28, 28, 1)\n",
            "(6974, 24)\n",
            "(159, 24)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8I5qxKuPc6V"
      },
      "source": [
        "#### CNN with augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ydv19V402LZf"
      },
      "outputs": [],
      "source": [
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.1, # Randomly zoom image \n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=False,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "\n",
        "\n",
        "\n",
        "datagen.fit(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLLF0_5B59ek"
      },
      "outputs": [],
      "source": [
        "# Set a learning rate annealer\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n",
        "                                            patience=3, \n",
        "                                            verbose=1, \n",
        "                                            factor=0.5, \n",
        "                                            min_lr=0.00001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pqun26fn2gQC",
        "outputId": "102279d2-9c60-4395-99d7-6982446fcc08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_36 (Conv2D)          (None, 28, 28, 32)        832       \n",
            "                                                                 \n",
            " conv2d_37 (Conv2D)          (None, 28, 28, 32)        25632     \n",
            "                                                                 \n",
            " max_pooling2d_18 (MaxPoolin  (None, 14, 14, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_18 (Bat  (None, 14, 14, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_24 (Dropout)        (None, 14, 14, 32)        0         \n",
            "                                                                 \n",
            " conv2d_38 (Conv2D)          (None, 14, 14, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_39 (Conv2D)          (None, 14, 14, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_19 (MaxPoolin  (None, 7, 7, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_19 (Bat  (None, 7, 7, 64)         256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_25 (Dropout)        (None, 7, 7, 64)          0         \n",
            "                                                                 \n",
            " conv2d_40 (Conv2D)          (None, 7, 7, 128)         73856     \n",
            "                                                                 \n",
            " conv2d_41 (Conv2D)          (None, 7, 7, 128)         147584    \n",
            "                                                                 \n",
            " batch_normalization_20 (Bat  (None, 7, 7, 128)        512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_20 (MaxPoolin  (None, 4, 4, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_26 (Dropout)        (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 512)               1049088   \n",
            "                                                                 \n",
            " dropout_27 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 24)                12312     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,365,624\n",
            "Trainable params: 1,365,176\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ],
      "source": [
        "# architecture\n",
        "# Set the CNN model \n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu', input_shape = (28,28,1)))\n",
        "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation = \"relu\"))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(24, activation = \"softmax\"))\n",
        "model.summary()\n",
        "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agrAieb-3u8u",
        "outputId": "06f5d6f5-7f30-46f4-a5dc-392a70ec652d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-c122dd20a34e>:15: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "54/54 [==============================] - ETA: 0s - loss: 3.4181 - accuracy: 0.0551\n",
            "Epoch 1: val_accuracy improved from -inf to 0.05031, saving model to best.h5\n",
            "54/54 [==============================] - 8s 47ms/step - loss: 3.4181 - accuracy: 0.0551 - val_loss: 3.2702 - val_accuracy: 0.0503 - lr: 0.0010\n",
            "Epoch 2/30\n",
            "53/54 [============================>.] - ETA: 0s - loss: 3.1354 - accuracy: 0.0681\n",
            "Epoch 2: val_accuracy did not improve from 0.05031\n",
            "54/54 [==============================] - 2s 42ms/step - loss: 3.1345 - accuracy: 0.0686 - val_loss: 3.5442 - val_accuracy: 0.0503 - lr: 0.0010\n",
            "Epoch 3/30\n",
            "53/54 [============================>.] - ETA: 0s - loss: 3.0385 - accuracy: 0.0999\n",
            "Epoch 3: val_accuracy did not improve from 0.05031\n",
            "54/54 [==============================] - 3s 62ms/step - loss: 3.0369 - accuracy: 0.1002 - val_loss: 3.4320 - val_accuracy: 0.0503 - lr: 0.0010\n",
            "Epoch 4/30\n",
            "54/54 [==============================] - ETA: 0s - loss: 2.9052 - accuracy: 0.1322\n",
            "Epoch 4: val_accuracy did not improve from 0.05031\n",
            "\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "54/54 [==============================] - 3s 47ms/step - loss: 2.9052 - accuracy: 0.1322 - val_loss: 3.6051 - val_accuracy: 0.0252 - lr: 0.0010\n",
            "Epoch 5/30\n",
            "54/54 [==============================] - ETA: 0s - loss: 2.6735 - accuracy: 0.1931\n",
            "Epoch 5: val_accuracy did not improve from 0.05031\n",
            "54/54 [==============================] - 2s 42ms/step - loss: 2.6735 - accuracy: 0.1931 - val_loss: 3.6409 - val_accuracy: 0.0503 - lr: 5.0000e-04\n",
            "Epoch 6/30\n",
            "54/54 [==============================] - ETA: 0s - loss: 2.4326 - accuracy: 0.2520\n",
            "Epoch 6: val_accuracy improved from 0.05031 to 0.06918, saving model to best.h5\n",
            "54/54 [==============================] - 2s 45ms/step - loss: 2.4326 - accuracy: 0.2520 - val_loss: 3.6153 - val_accuracy: 0.0692 - lr: 5.0000e-04\n",
            "Epoch 7/30\n",
            "54/54 [==============================] - ETA: 0s - loss: 2.1745 - accuracy: 0.3160\n",
            "Epoch 7: val_accuracy improved from 0.06918 to 0.12579, saving model to best.h5\n",
            "54/54 [==============================] - 2s 44ms/step - loss: 2.1745 - accuracy: 0.3160 - val_loss: 3.2128 - val_accuracy: 0.1258 - lr: 5.0000e-04\n",
            "Epoch 8/30\n",
            "54/54 [==============================] - ETA: 0s - loss: 1.8936 - accuracy: 0.3970\n",
            "Epoch 8: val_accuracy improved from 0.12579 to 0.17610, saving model to best.h5\n",
            "54/54 [==============================] - 6s 105ms/step - loss: 1.8936 - accuracy: 0.3970 - val_loss: 3.2564 - val_accuracy: 0.1761 - lr: 5.0000e-04\n",
            "Epoch 9/30\n",
            "54/54 [==============================] - ETA: 0s - loss: 1.6170 - accuracy: 0.4771\n",
            "Epoch 9: val_accuracy did not improve from 0.17610\n",
            "54/54 [==============================] - 2s 43ms/step - loss: 1.6170 - accuracy: 0.4771 - val_loss: 3.4461 - val_accuracy: 0.1761 - lr: 5.0000e-04\n",
            "Epoch 10/30\n",
            "54/54 [==============================] - ETA: 0s - loss: 1.3791 - accuracy: 0.5491\n",
            "Epoch 10: val_accuracy improved from 0.17610 to 0.25157, saving model to best.h5\n",
            "54/54 [==============================] - 2s 46ms/step - loss: 1.3791 - accuracy: 0.5491 - val_loss: 3.0871 - val_accuracy: 0.2516 - lr: 5.0000e-04\n",
            "Epoch 11/30\n",
            "54/54 [==============================] - ETA: 0s - loss: 1.1467 - accuracy: 0.6294\n",
            "Epoch 11: val_accuracy improved from 0.25157 to 0.27673, saving model to best.h5\n",
            "54/54 [==============================] - 4s 70ms/step - loss: 1.1467 - accuracy: 0.6294 - val_loss: 2.7548 - val_accuracy: 0.2767 - lr: 5.0000e-04\n",
            "Epoch 12/30\n",
            "54/54 [==============================] - ETA: 0s - loss: 0.9685 - accuracy: 0.6750\n",
            "Epoch 12: val_accuracy improved from 0.27673 to 0.31447, saving model to best.h5\n",
            "54/54 [==============================] - 2s 44ms/step - loss: 0.9685 - accuracy: 0.6750 - val_loss: 2.6416 - val_accuracy: 0.3145 - lr: 5.0000e-04\n",
            "Epoch 13/30\n",
            "53/54 [============================>.] - ETA: 0s - loss: 0.8420 - accuracy: 0.7209\n",
            "Epoch 13: val_accuracy improved from 0.31447 to 0.32704, saving model to best.h5\n",
            "54/54 [==============================] - 2s 45ms/step - loss: 0.8419 - accuracy: 0.7207 - val_loss: 2.7012 - val_accuracy: 0.3270 - lr: 5.0000e-04\n",
            "Epoch 14/30\n",
            "53/54 [============================>.] - ETA: 0s - loss: 0.7062 - accuracy: 0.7624\n",
            "Epoch 14: val_accuracy improved from 0.32704 to 0.35220, saving model to best.h5\n",
            "54/54 [==============================] - 2s 45ms/step - loss: 0.7053 - accuracy: 0.7629 - val_loss: 2.5793 - val_accuracy: 0.3522 - lr: 5.0000e-04\n",
            "Epoch 15/30\n",
            "54/54 [==============================] - ETA: 0s - loss: 0.5970 - accuracy: 0.8006\n",
            "Epoch 15: val_accuracy improved from 0.35220 to 0.38994, saving model to best.h5\n",
            "54/54 [==============================] - 3s 63ms/step - loss: 0.5970 - accuracy: 0.8006 - val_loss: 2.6011 - val_accuracy: 0.3899 - lr: 5.0000e-04\n",
            "Epoch 16/30\n",
            "53/54 [============================>.] - ETA: 0s - loss: 0.5514 - accuracy: 0.8166\n",
            "Epoch 16: val_accuracy did not improve from 0.38994\n",
            "54/54 [==============================] - 3s 50ms/step - loss: 0.5525 - accuracy: 0.8168 - val_loss: 2.7279 - val_accuracy: 0.3333 - lr: 5.0000e-04\n",
            "Epoch 17/30\n",
            "54/54 [==============================] - ETA: 0s - loss: 0.4726 - accuracy: 0.8436\n",
            "Epoch 17: val_accuracy improved from 0.38994 to 0.40252, saving model to best.h5\n",
            "54/54 [==============================] - 2s 44ms/step - loss: 0.4726 - accuracy: 0.8436 - val_loss: 2.5068 - val_accuracy: 0.4025 - lr: 5.0000e-04\n",
            "Epoch 18/30\n",
            "53/54 [============================>.] - ETA: 0s - loss: 0.4231 - accuracy: 0.8549\n",
            "Epoch 18: val_accuracy did not improve from 0.40252\n",
            "54/54 [==============================] - 2s 42ms/step - loss: 0.4244 - accuracy: 0.8552 - val_loss: 2.7316 - val_accuracy: 0.3899 - lr: 5.0000e-04\n",
            "Epoch 19/30\n",
            "53/54 [============================>.] - ETA: 0s - loss: 0.4004 - accuracy: 0.8656\n",
            "Epoch 19: val_accuracy did not improve from 0.40252\n",
            "54/54 [==============================] - 3s 54ms/step - loss: 0.3994 - accuracy: 0.8659 - val_loss: 2.6846 - val_accuracy: 0.3836 - lr: 5.0000e-04\n",
            "Epoch 20/30\n",
            "54/54 [==============================] - ETA: 0s - loss: 0.3439 - accuracy: 0.8864\n",
            "Epoch 20: val_accuracy did not improve from 0.40252\n",
            "\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "54/54 [==============================] - 3s 57ms/step - loss: 0.3439 - accuracy: 0.8864 - val_loss: 2.7614 - val_accuracy: 0.3836 - lr: 5.0000e-04\n",
            "Epoch 21/30\n",
            "54/54 [==============================] - ETA: 0s - loss: 0.2997 - accuracy: 0.9015\n",
            "Epoch 21: val_accuracy did not improve from 0.40252\n",
            "54/54 [==============================] - 2s 42ms/step - loss: 0.2997 - accuracy: 0.9015 - val_loss: 2.9291 - val_accuracy: 0.3774 - lr: 2.5000e-04\n",
            "Epoch 22/30\n",
            "53/54 [============================>.] - ETA: 0s - loss: 0.2767 - accuracy: 0.9092\n",
            "Epoch 22: val_accuracy did not improve from 0.40252\n",
            "54/54 [==============================] - 2s 41ms/step - loss: 0.2756 - accuracy: 0.9093 - val_loss: 2.8812 - val_accuracy: 0.3962 - lr: 2.5000e-04\n",
            "Epoch 23/30\n",
            "54/54 [==============================] - ETA: 0s - loss: 0.2548 - accuracy: 0.9147\n",
            "Epoch 23: val_accuracy did not improve from 0.40252\n",
            "\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "54/54 [==============================] - 2s 42ms/step - loss: 0.2548 - accuracy: 0.9147 - val_loss: 2.8176 - val_accuracy: 0.3962 - lr: 2.5000e-04\n",
            "Epoch 24/30\n",
            "54/54 [==============================] - ETA: 0s - loss: 0.2229 - accuracy: 0.9278\n",
            "Epoch 24: val_accuracy did not improve from 0.40252\n",
            "54/54 [==============================] - 3s 64ms/step - loss: 0.2229 - accuracy: 0.9278 - val_loss: 3.0207 - val_accuracy: 0.3585 - lr: 1.2500e-04\n",
            "Epoch 25/30\n",
            "54/54 [==============================] - ETA: 0s - loss: 0.2021 - accuracy: 0.9313\n",
            "Epoch 25: val_accuracy did not improve from 0.40252\n",
            "54/54 [==============================] - 2s 41ms/step - loss: 0.2021 - accuracy: 0.9313 - val_loss: 3.0784 - val_accuracy: 0.3711 - lr: 1.2500e-04\n",
            "Epoch 26/30\n",
            "54/54 [==============================] - ETA: 0s - loss: 0.2030 - accuracy: 0.9309\n",
            "Epoch 26: val_accuracy did not improve from 0.40252\n",
            "\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "54/54 [==============================] - 2s 41ms/step - loss: 0.2030 - accuracy: 0.9309 - val_loss: 3.0422 - val_accuracy: 0.3899 - lr: 1.2500e-04\n",
            "Epoch 27/30\n",
            "53/54 [============================>.] - ETA: 0s - loss: 0.1853 - accuracy: 0.9384\n",
            "Epoch 27: val_accuracy did not improve from 0.40252\n",
            "54/54 [==============================] - 2s 40ms/step - loss: 0.1860 - accuracy: 0.9381 - val_loss: 3.1428 - val_accuracy: 0.3899 - lr: 6.2500e-05\n",
            "Epoch 27: early stopping\n"
          ]
        }
      ],
      "source": [
        "epochs = 30\n",
        "batch_size = 128\n",
        "\n",
        "\n",
        "model_checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=\"best.h5\",\n",
        "    monitor='val_accuracy', \n",
        "    verbose=1, \n",
        "    save_best_only=True, \n",
        "    mode='max')\n",
        "\n",
        "es = EarlyStopping(monitor=\"val_loss\", mode=\"min\", verbose=1, patience=10)\n",
        "\n",
        "# Fit the model\n",
        "history = model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size),\n",
        "                              epochs = epochs, validation_data = (X_test, y_test),steps_per_epoch=X_train.shape[0] // batch_size,\n",
        "                              verbose = 1,   callbacks=[model_checkpoint_callback,learning_rate_reduction,es])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYi1Or2e6nyg",
        "outputId": "f11e2eef-72d5-4771-9dc8-dbbf2b96f35d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 3ms/step\n"
          ]
        }
      ],
      "source": [
        "results = model.predict(X_test)\n",
        "y_pred = np.argmax(results,axis = 1) \n",
        "y_true = np.argmax(y_test,axis = 1) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXikuqQYPgTq"
      },
      "source": [
        "#### Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLTWqAUsEm6k",
        "outputId": "0750d2a0-5bd1-47b2-8a34-e924de0234a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      0.40      0.36         5\n",
            "           1       0.27      0.60      0.37         5\n",
            "           2       0.75      0.25      0.38        12\n",
            "           3       0.50      0.20      0.29         5\n",
            "           4       0.33      0.57      0.42         7\n",
            "           5       0.50      0.67      0.57         6\n",
            "           6       0.00      0.00      0.00         5\n",
            "           7       0.33      0.09      0.14        11\n",
            "           8       0.60      0.60      0.60         5\n",
            "           9       0.50      0.33      0.40         6\n",
            "          10       0.40      0.67      0.50         3\n",
            "          11       0.00      0.00      0.00         3\n",
            "          12       0.00      0.00      0.00         5\n",
            "          13       0.67      0.25      0.36         8\n",
            "          14       0.33      0.14      0.20         7\n",
            "          15       0.20      0.17      0.18         6\n",
            "          16       0.33      0.25      0.29         8\n",
            "          17       0.33      0.33      0.33         6\n",
            "          18       0.22      0.33      0.27         6\n",
            "          19       0.38      0.75      0.50         4\n",
            "          20       0.78      0.88      0.82         8\n",
            "          21       0.78      0.70      0.74        10\n",
            "          22       0.17      0.12      0.14         8\n",
            "          23       0.82      0.90      0.86        10\n",
            "\n",
            "    accuracy                           0.39       159\n",
            "   macro avg       0.40      0.38      0.36       159\n",
            "weighted avg       0.44      0.39      0.39       159\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_true, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the ROC AUC using the micro-averaging method\n",
        "roc_auc = roc_auc_score(y_test, results, multi_class='ovr', average='micro')\n",
        "print(\"ROC AUC score (micro average):\", roc_auc)\n",
        "roc_auc = roc_auc_score(y_test, results, multi_class='ovr', average='macro')\n",
        "print(\"ROC AUC score (macro average):\", roc_auc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWwGgvhyZCvN",
        "outputId": "dfdc37d0-bd48-424a-8583-382b87118f19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC AUC score (micro average): 0.9164469622314748\n",
            "ROC AUC score (macro average): 0.913476257382485\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKjvX_xZPiyd"
      },
      "source": [
        "#### Prediction and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UEEggtZgP85l"
      },
      "outputs": [],
      "source": [
        "# test model prediction using the sign language letter m\n",
        "img = Image.open('m.png')\n",
        "img = img.resize((28, 28), Image.ANTIALIAS)\n",
        "img = img.convert('L')\n",
        "img_array = np.array(img)\n",
        "img_array = img_array/255.0\n",
        "img_array = img_array.reshape(-1, 28, 28, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "-p0UFI3KQ60e",
        "outputId": "ad06d660-5564-4b31-ee20-4afdaae1a1bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 46ms/step\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'m'"
            ]
          },
          "execution_count": 177,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results = model.predict(img_array)\n",
        "y_pred = np.argmax(results,axis = 1)\n",
        "txt[y_pred[0]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fl9cpWnskqh"
      },
      "source": [
        "#### After hyperparameter tuning, train it with the whole data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8sJtvnz4SYl"
      },
      "outputs": [],
      "source": [
        "# Load X and y\n",
        "output_dir = '/content/drive/MyDrive/IS4242/dump/'\n",
        "X = joblib.load(output_dir+'X.pkl')\n",
        "y = joblib.load(output_dir+'y.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTRCQpJxsKwV"
      },
      "outputs": [],
      "source": [
        "# Initialize augmented data list\n",
        "augmentX = []\n",
        "augmenty = []\n",
        "\n",
        "# Iterate through data set\n",
        "for i in range(len(X)):\n",
        "  # Do 10 iterations of random transformation and add to augmented dataset\n",
        "  for j in (range(10)):\n",
        "      transformed = transform(image=X[i])\n",
        "      augmentX.append(transformed['image'])\n",
        "      augmenty.append(y[i])\n",
        "\n",
        "augmentX = np.array(augmentX)\n",
        "augmenty = np.array(augmenty)\n",
        "\n",
        "#Concatenate original data with augmented set\n",
        "X = np.concatenate([X,augmentX])\n",
        "y = np.concatenate([y,augmenty])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvdlw0Wusfq_"
      },
      "outputs": [],
      "source": [
        "# Resize and reshape X\n",
        "X = X/255.0\n",
        "X = X.reshape(-1, 28, 28, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5dDlAFUstQo"
      },
      "outputs": [],
      "source": [
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.1, # Randomly zoom image \n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=False,\n",
        "        brightness_range=[0.8,1.2],\n",
        "        vertical_flip=False)\n",
        "\n",
        "\n",
        "datagen.fit(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfLB_Lz81HOz",
        "outputId": "5a5be516-fd07-4809-af34-36f5c4bdb91d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu', input_shape = (28,28,1)))\n",
        "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2) , padding = 'same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2) , padding = 'same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D((2,2) , padding = 'same'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation = \"relu\"))\n",
        "model.add(Dense(512, activation = \"relu\"))\n",
        "model.add(Dense(24, activation = \"softmax\"))\n",
        "\n",
        "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1OIWSo7REu0"
      },
      "outputs": [],
      "source": [
        "epochs = 30\n",
        "batch_size = 64\n",
        "\n",
        "# Fit the model\n",
        "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit_generator(datagen.flow(X, y, batch_size=batch_size),epochs = epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Prediction and evaluation"
      ],
      "metadata": {
        "id": "qmLdeA2hzTrv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jXsERtDtypeL"
      },
      "outputs": [],
      "source": [
        "# test model prediction using the sign language letter m\n",
        "img = Image.open('m.png')\n",
        "img = img.resize((28, 28), Image.ANTIALIAS)\n",
        "img = img.convert('L')\n",
        "img_array = np.array(img)\n",
        "img_array = img_array/255.0\n",
        "img_array = img_array.reshape(-1, 28, 28, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "pCnbAKysypeM",
        "outputId": "ad06d660-5564-4b31-ee20-4afdaae1a1bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 46ms/step\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'m'"
            ]
          },
          "execution_count": 177,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results = model.predict(img_array)\n",
        "y_pred = np.argmax(results,axis = 1)\n",
        "txt[y_pred[0]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBlPrT1E6DhA"
      },
      "source": [
        "## Using MediaPipe\n",
        "This section contains the model using MediaPipe's hand landmark detection algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGA5bHxXLTah",
        "outputId": "1b28d048-f8e0-4ff1-fcca-9c3c489af71e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.9.2.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.6/33.6 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.9/dist-packages (from mediapipe) (3.20.3)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.9/dist-packages (from mediapipe) (22.2.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from mediapipe) (3.7.1)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from mediapipe) (23.3.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from mediapipe) (1.22.4)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.9/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.9/dist-packages (from mediapipe) (4.7.0.72)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (4.39.3)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (3.0.9)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (1.0.7)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (5.12.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (8.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (0.11.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->mediapipe) (3.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
            "Installing collected packages: mediapipe\n",
            "Successfully installed mediapipe-0.9.2.1\n"
          ]
        }
      ],
      "source": [
        "# Install MediaPipe\n",
        "!pip install mediapipe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7WmCdMMKdZj"
      },
      "outputs": [],
      "source": [
        "# For capturing hand coordinates\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import mediapipe as mp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmW6L-fwKjxN"
      },
      "outputs": [],
      "source": [
        "# For processing data\n",
        "import csv\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm \n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLRHkA3YMfH6"
      },
      "source": [
        "#### Convert image data to matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bE4Fz8zMYup",
        "outputId": "d5665bcc-6f90-4002-8164-58029deb2e0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFye1EVbJXhX"
      },
      "outputs": [],
      "source": [
        "# Use the albumentations library for augmentation pipeline\n",
        "import albumentations as A\n",
        "\n",
        "transform = A.Compose([\n",
        "    # Randomly adjust the brightness of the image\n",
        "    A.RandomBrightnessContrast(),\n",
        "        \n",
        "    # Randomly apply scaling, translation and shearing\n",
        "    A.Affine(scale=[0.8,1.2],translate_percent=0.05, shear=0.2, keep_ratio=True, p=0.5),\n",
        "    \n",
        "    # Randomly apply rotation\n",
        "    A.Rotate(limit=10)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a-TTGhMJXhY",
        "outputId": "d023a3b6-fc51-4694-9003-c40478d09272"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1221/1221 [02:59<00:00,  6.80it/s]\n"
          ]
        }
      ],
      "source": [
        "# Define directory path and initialize empty lists\n",
        "folder_name = '/content/drive/MyDrive/IS4242/data'\n",
        "path = folder_name\n",
        "img_list = []\n",
        "label_list = []\n",
        "txt = 'abcdefghiklmnopqrstuvwxy'\n",
        "\n",
        "# Iterate through files listed in the directory\n",
        "for i in tqdm(range(len(os.listdir(path)))):\n",
        "  filename = os.listdir(path)[i]\n",
        "\n",
        "  # If filename is of  type .jpg or .png, split the filename and take the first strings before a '-' or '_'\n",
        "  if filename.endswith(('.jpg','.png')):\n",
        "      label_name = re.split(r'[-_]', filename)[0].lower()\n",
        "      if label_name not in txt:\n",
        "        continue\n",
        "\n",
        "      # Append the splitted filenames as labels\n",
        "      label_list.append(label_name)\n",
        "\n",
        "      # Open, resize image into 28 x 28 pixels and convert into greyscale then into np.array\n",
        "      img = Image.open(os.path.join(path, filename))\n",
        "      img = img.resize((224, 224), Image.ANTIALIAS) # bigger size\n",
        "      img = img.convert('L')\n",
        "      img_array = np.array(img)\n",
        "      \n",
        "      img_list.append(img_array)\n",
        "\n",
        "# Convert img_list into np.array and store as X \n",
        "X = np.array(img_list)\n",
        "\n",
        "# Convert y data into np.array and use one-hot encoding to store the labels\n",
        "y = np.array(label_list)\n",
        "y = np.array(list(map(lambda x:txt.find(x), y)))\n",
        "y = to_categorical(y)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir = '/content/drive/MyDrive/IS4242/dump/'\n",
        "joblib.dump(X,output_dir+'X_224.pkl')\n",
        "joblib.dump(y,output_dir+'y_224.pkl')"
      ],
      "metadata": {
        "id": "Q4OIr-QSmmAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mw9kBbmp-u7Y"
      },
      "outputs": [],
      "source": [
        "output_dir = '/content/drive/MyDrive/IS4242/dump/'\n",
        "X = joblib.load(output_dir+'X_224.pkl')\n",
        "y = joblib.load(output_dir+'y_224.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BerTO8-u-wle",
        "outputId": "ca164529-b955-43ee-c4c6-4e20d3c7d487"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "817"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "len(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1LgfWyZQQjQ"
      },
      "source": [
        "#### Train test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSymOBG_ZYT8"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCEjPzK5QU3Z"
      },
      "source": [
        "#### Augmentation only on train data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8ZWfcrm-9ZA"
      },
      "outputs": [],
      "source": [
        "# Initialize augmented datalist\n",
        "augmented_X = []\n",
        "augmented_y = []\n",
        "\n",
        "# Loop through the train data set\n",
        "for i in range(len(X_train)):\n",
        "  \n",
        "  # Perform augmentation and transformation 10 times for each data point\n",
        "  for j in (range(10)):\n",
        "      transformed = transform(image=X_train[i])\n",
        "      augmented_X.append(transformed['image'])\n",
        "      augmented_y.append(y_train[i])\n",
        "\n",
        "# Concatenate original set with augmentation set\n",
        "augmented_X = np.array(augmented_X)\n",
        "augmented_y = np.array(augmented_y)\n",
        "X_train = np.concatenate([X_train,augmented_X])\n",
        "y_train = np.concatenate([y_train,augmented_y])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save augmented data as pickle file\n",
        "output_dir = '/content/drive/MyDrive/IS4242/dump/'\n",
        "joblib.dump(X_train,output_dir+'X_224_augmented.pkl')\n",
        "joblib.dump(y_train,output_dir+'y_224_augmented.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnEUQ-LLnkvy",
        "outputId": "e40f3748-a421-4b95-a97e-cdfb7104dcdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/IS4242/dump/y_224_augmented.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load augmented data\n",
        "output_dir = '/content/drive/MyDrive/IS4242/dump/'\n",
        "X_train = joblib.load(output_dir+'X_224_augmented.pkl')\n",
        "y_train = joblib.load(output_dir+'y_224_augmented.pkl')"
      ],
      "metadata": {
        "id": "JusAEZyGnobB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJefejTyQYTO"
      },
      "source": [
        "#### Generate dataset of hand points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNFO4k4HSglj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06f4533c-d763-46fc-af74-17488f1480e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7183/7183 [05:13<00:00, 22.90it/s]\n"
          ]
        }
      ],
      "source": [
        "# Initialize MediPipe drawing utils and hand detection models\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_hands = mp.solutions.hands\n",
        "\n",
        "# Initialize lists to store features and labels\n",
        "data = []\n",
        "labels = []\n",
        "count = 0 # keeps track of failed detections\n",
        "\n",
        "with mp_hands.Hands(static_image_mode =True, max_num_hands = 2, min_detection_confidence=0.5) as hands:\n",
        "    for i in tqdm(range(len(X_train))):\n",
        "        # Load the image and extract its features\n",
        "            results = hands.process(cv2.cvtColor(cv2.flip(X_train[i],1), cv2.COLOR_BGR2RGB))\n",
        "            try:\n",
        "                # Extract Hand landmarks\n",
        "                for hand_landmark in results.multi_hand_landmarks:\n",
        "                    right_hand = hand_landmark.landmark\n",
        "                right_hand_row = list(np.array([[landmark.x, landmark.y] for landmark in right_hand]).flatten())\n",
        "                # Concate rows\n",
        "                row = right_hand_row\n",
        "\n",
        "                # Extract the label from the image filename (e.g. \"A.jpg\")\n",
        "                label = y_train[i]\n",
        "\n",
        "                data.append(row)\n",
        "                labels.append(label)\n",
        "            except Exception as e:\n",
        "                count += 1\n",
        "                continue\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "eit7571EYcuE",
        "outputId": "c2ccfb6c-2a45-4d9d-d14a-f4bcb5cbdb0a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3631d46c-4797-4147-8a91-cb5d831aa6ab\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.570230</td>\n",
              "      <td>0.700385</td>\n",
              "      <td>0.460918</td>\n",
              "      <td>0.601834</td>\n",
              "      <td>0.385230</td>\n",
              "      <td>0.526549</td>\n",
              "      <td>0.322623</td>\n",
              "      <td>0.470859</td>\n",
              "      <td>0.301588</td>\n",
              "      <td>0.408549</td>\n",
              "      <td>...</td>\n",
              "      <td>0.434779</td>\n",
              "      <td>0.504095</td>\n",
              "      <td>0.549578</td>\n",
              "      <td>0.469310</td>\n",
              "      <td>0.416643</td>\n",
              "      <td>0.467967</td>\n",
              "      <td>0.423916</td>\n",
              "      <td>0.518278</td>\n",
              "      <td>0.466331</td>\n",
              "      <td>0.533848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.446183</td>\n",
              "      <td>0.796893</td>\n",
              "      <td>0.341452</td>\n",
              "      <td>0.681229</td>\n",
              "      <td>0.304357</td>\n",
              "      <td>0.500339</td>\n",
              "      <td>0.314089</td>\n",
              "      <td>0.366598</td>\n",
              "      <td>0.315794</td>\n",
              "      <td>0.253817</td>\n",
              "      <td>...</td>\n",
              "      <td>0.488412</td>\n",
              "      <td>0.601652</td>\n",
              "      <td>0.734732</td>\n",
              "      <td>0.564161</td>\n",
              "      <td>0.699286</td>\n",
              "      <td>0.469736</td>\n",
              "      <td>0.620621</td>\n",
              "      <td>0.544259</td>\n",
              "      <td>0.574593</td>\n",
              "      <td>0.615079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.554823</td>\n",
              "      <td>0.467337</td>\n",
              "      <td>0.477951</td>\n",
              "      <td>0.500206</td>\n",
              "      <td>0.370337</td>\n",
              "      <td>0.497704</td>\n",
              "      <td>0.303738</td>\n",
              "      <td>0.458727</td>\n",
              "      <td>0.319072</td>\n",
              "      <td>0.396847</td>\n",
              "      <td>...</td>\n",
              "      <td>0.466813</td>\n",
              "      <td>0.410920</td>\n",
              "      <td>0.478718</td>\n",
              "      <td>0.277710</td>\n",
              "      <td>0.441688</td>\n",
              "      <td>0.218711</td>\n",
              "      <td>0.420079</td>\n",
              "      <td>0.179862</td>\n",
              "      <td>0.393535</td>\n",
              "      <td>0.143242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.421717</td>\n",
              "      <td>0.593616</td>\n",
              "      <td>0.332333</td>\n",
              "      <td>0.543942</td>\n",
              "      <td>0.278878</td>\n",
              "      <td>0.457589</td>\n",
              "      <td>0.282298</td>\n",
              "      <td>0.384428</td>\n",
              "      <td>0.314716</td>\n",
              "      <td>0.334537</td>\n",
              "      <td>...</td>\n",
              "      <td>0.391403</td>\n",
              "      <td>0.521059</td>\n",
              "      <td>0.528068</td>\n",
              "      <td>0.395230</td>\n",
              "      <td>0.475645</td>\n",
              "      <td>0.423229</td>\n",
              "      <td>0.459146</td>\n",
              "      <td>0.468935</td>\n",
              "      <td>0.459199</td>\n",
              "      <td>0.488524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.651359</td>\n",
              "      <td>0.619728</td>\n",
              "      <td>0.656911</td>\n",
              "      <td>0.514619</td>\n",
              "      <td>0.602316</td>\n",
              "      <td>0.457691</td>\n",
              "      <td>0.539696</td>\n",
              "      <td>0.429281</td>\n",
              "      <td>0.491382</td>\n",
              "      <td>0.435781</td>\n",
              "      <td>...</td>\n",
              "      <td>0.391995</td>\n",
              "      <td>0.521948</td>\n",
              "      <td>0.437633</td>\n",
              "      <td>0.637292</td>\n",
              "      <td>0.367256</td>\n",
              "      <td>0.589515</td>\n",
              "      <td>0.384333</td>\n",
              "      <td>0.575371</td>\n",
              "      <td>0.412115</td>\n",
              "      <td>0.575475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3156</th>\n",
              "      <td>0.583231</td>\n",
              "      <td>0.452619</td>\n",
              "      <td>0.539714</td>\n",
              "      <td>0.455225</td>\n",
              "      <td>0.495395</td>\n",
              "      <td>0.492904</td>\n",
              "      <td>0.479851</td>\n",
              "      <td>0.551855</td>\n",
              "      <td>0.483757</td>\n",
              "      <td>0.602373</td>\n",
              "      <td>...</td>\n",
              "      <td>0.545168</td>\n",
              "      <td>0.576425</td>\n",
              "      <td>0.487555</td>\n",
              "      <td>0.524171</td>\n",
              "      <td>0.515908</td>\n",
              "      <td>0.578480</td>\n",
              "      <td>0.545968</td>\n",
              "      <td>0.580548</td>\n",
              "      <td>0.566784</td>\n",
              "      <td>0.575146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3157</th>\n",
              "      <td>0.562530</td>\n",
              "      <td>0.498690</td>\n",
              "      <td>0.511731</td>\n",
              "      <td>0.506001</td>\n",
              "      <td>0.454501</td>\n",
              "      <td>0.544319</td>\n",
              "      <td>0.426224</td>\n",
              "      <td>0.600555</td>\n",
              "      <td>0.422746</td>\n",
              "      <td>0.650416</td>\n",
              "      <td>...</td>\n",
              "      <td>0.465353</td>\n",
              "      <td>0.691858</td>\n",
              "      <td>0.439111</td>\n",
              "      <td>0.577353</td>\n",
              "      <td>0.453883</td>\n",
              "      <td>0.642066</td>\n",
              "      <td>0.476830</td>\n",
              "      <td>0.662664</td>\n",
              "      <td>0.497206</td>\n",
              "      <td>0.675142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3158</th>\n",
              "      <td>0.563214</td>\n",
              "      <td>0.502042</td>\n",
              "      <td>0.515475</td>\n",
              "      <td>0.514002</td>\n",
              "      <td>0.460635</td>\n",
              "      <td>0.550754</td>\n",
              "      <td>0.430844</td>\n",
              "      <td>0.599683</td>\n",
              "      <td>0.423958</td>\n",
              "      <td>0.642966</td>\n",
              "      <td>...</td>\n",
              "      <td>0.467354</td>\n",
              "      <td>0.680093</td>\n",
              "      <td>0.444119</td>\n",
              "      <td>0.574531</td>\n",
              "      <td>0.456100</td>\n",
              "      <td>0.633061</td>\n",
              "      <td>0.477790</td>\n",
              "      <td>0.649635</td>\n",
              "      <td>0.497778</td>\n",
              "      <td>0.658029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3159</th>\n",
              "      <td>0.583231</td>\n",
              "      <td>0.452619</td>\n",
              "      <td>0.539714</td>\n",
              "      <td>0.455225</td>\n",
              "      <td>0.495395</td>\n",
              "      <td>0.492904</td>\n",
              "      <td>0.479851</td>\n",
              "      <td>0.551855</td>\n",
              "      <td>0.483757</td>\n",
              "      <td>0.602373</td>\n",
              "      <td>...</td>\n",
              "      <td>0.545168</td>\n",
              "      <td>0.576425</td>\n",
              "      <td>0.487555</td>\n",
              "      <td>0.524171</td>\n",
              "      <td>0.515908</td>\n",
              "      <td>0.578480</td>\n",
              "      <td>0.545968</td>\n",
              "      <td>0.580548</td>\n",
              "      <td>0.566784</td>\n",
              "      <td>0.575146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3160</th>\n",
              "      <td>0.628690</td>\n",
              "      <td>0.473217</td>\n",
              "      <td>0.574249</td>\n",
              "      <td>0.468687</td>\n",
              "      <td>0.512486</td>\n",
              "      <td>0.497820</td>\n",
              "      <td>0.476601</td>\n",
              "      <td>0.542893</td>\n",
              "      <td>0.464293</td>\n",
              "      <td>0.584233</td>\n",
              "      <td>...</td>\n",
              "      <td>0.495103</td>\n",
              "      <td>0.641691</td>\n",
              "      <td>0.490426</td>\n",
              "      <td>0.535288</td>\n",
              "      <td>0.482897</td>\n",
              "      <td>0.591316</td>\n",
              "      <td>0.492581</td>\n",
              "      <td>0.618815</td>\n",
              "      <td>0.505936</td>\n",
              "      <td>0.639760</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3161 rows × 42 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3631d46c-4797-4147-8a91-cb5d831aa6ab')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3631d46c-4797-4147-8a91-cb5d831aa6ab button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3631d46c-4797-4147-8a91-cb5d831aa6ab');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            0         1         2         3         4         5         6   \\\n",
              "0     0.570230  0.700385  0.460918  0.601834  0.385230  0.526549  0.322623   \n",
              "1     0.446183  0.796893  0.341452  0.681229  0.304357  0.500339  0.314089   \n",
              "2     0.554823  0.467337  0.477951  0.500206  0.370337  0.497704  0.303738   \n",
              "3     0.421717  0.593616  0.332333  0.543942  0.278878  0.457589  0.282298   \n",
              "4     0.651359  0.619728  0.656911  0.514619  0.602316  0.457691  0.539696   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "3156  0.583231  0.452619  0.539714  0.455225  0.495395  0.492904  0.479851   \n",
              "3157  0.562530  0.498690  0.511731  0.506001  0.454501  0.544319  0.426224   \n",
              "3158  0.563214  0.502042  0.515475  0.514002  0.460635  0.550754  0.430844   \n",
              "3159  0.583231  0.452619  0.539714  0.455225  0.495395  0.492904  0.479851   \n",
              "3160  0.628690  0.473217  0.574249  0.468687  0.512486  0.497820  0.476601   \n",
              "\n",
              "            7         8         9   ...        32        33        34  \\\n",
              "0     0.470859  0.301588  0.408549  ...  0.434779  0.504095  0.549578   \n",
              "1     0.366598  0.315794  0.253817  ...  0.488412  0.601652  0.734732   \n",
              "2     0.458727  0.319072  0.396847  ...  0.466813  0.410920  0.478718   \n",
              "3     0.384428  0.314716  0.334537  ...  0.391403  0.521059  0.528068   \n",
              "4     0.429281  0.491382  0.435781  ...  0.391995  0.521948  0.437633   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "3156  0.551855  0.483757  0.602373  ...  0.545168  0.576425  0.487555   \n",
              "3157  0.600555  0.422746  0.650416  ...  0.465353  0.691858  0.439111   \n",
              "3158  0.599683  0.423958  0.642966  ...  0.467354  0.680093  0.444119   \n",
              "3159  0.551855  0.483757  0.602373  ...  0.545168  0.576425  0.487555   \n",
              "3160  0.542893  0.464293  0.584233  ...  0.495103  0.641691  0.490426   \n",
              "\n",
              "            35        36        37        38        39        40        41  \n",
              "0     0.469310  0.416643  0.467967  0.423916  0.518278  0.466331  0.533848  \n",
              "1     0.564161  0.699286  0.469736  0.620621  0.544259  0.574593  0.615079  \n",
              "2     0.277710  0.441688  0.218711  0.420079  0.179862  0.393535  0.143242  \n",
              "3     0.395230  0.475645  0.423229  0.459146  0.468935  0.459199  0.488524  \n",
              "4     0.637292  0.367256  0.589515  0.384333  0.575371  0.412115  0.575475  \n",
              "...        ...       ...       ...       ...       ...       ...       ...  \n",
              "3156  0.524171  0.515908  0.578480  0.545968  0.580548  0.566784  0.575146  \n",
              "3157  0.577353  0.453883  0.642066  0.476830  0.662664  0.497206  0.675142  \n",
              "3158  0.574531  0.456100  0.633061  0.477790  0.649635  0.497778  0.658029  \n",
              "3159  0.524171  0.515908  0.578480  0.545968  0.580548  0.566784  0.575146  \n",
              "3160  0.535288  0.482897  0.591316  0.492581  0.618815  0.505936  0.639760  \n",
              "\n",
              "[3161 rows x 42 columns]"
            ]
          },
          "execution_count": 130,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADTUKNgAY9uR",
        "outputId": "9956cb9b-d0d0-4f08-8366-ebeeba1055bc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/IS4242/dump/labels_cnn_train.pkl']"
            ]
          },
          "execution_count": 140,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Dumps mediapipe train data\n",
        "output_dir = f\"/content/drive/MyDrive/IS4242/dump/\"\n",
        "joblib.dump(data, output_dir+'data_cnn_train.pkl')\n",
        "joblib.dump(labels, output_dir+'labels_cnn_train.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrkf3ZG456IF"
      },
      "outputs": [],
      "source": [
        "# Loads mediapipe train data\n",
        "data = joblib.load(output_dir+'data_cnn_train.pkl')\n",
        "labels = joblib.load(output_dir+'labels_cnn_train.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Leiw72ko-Iy7"
      },
      "outputs": [],
      "source": [
        "# mediapipe conversion into landmark points for test data\n",
        "test_data = []\n",
        "test_label = []\n",
        "count = 0\n",
        "with mp_hands.Hands(static_image_mode =True, max_num_hands = 2, min_detection_confidence=0.5) as hands:\n",
        "    for i in tqdm(range(len(X_test))):\n",
        "        # Load the image and extract its features\n",
        "            results = hands.process(cv2.cvtColor(cv2.flip(X_test[i],1), cv2.COLOR_BGR2RGB))\n",
        "            try:\n",
        "                # Extract Hand landmarks\n",
        "                for hand_landmark in results.multi_hand_landmarks:\n",
        "                    right_hand = hand_landmark.landmark\n",
        "                right_hand_row = list(np.array([[landmark.x, landmark.y] for landmark in right_hand]).flatten())\n",
        "                # Concate rows\n",
        "                row = right_hand_row\n",
        "\n",
        "                # Extract the label from the image filename (e.g. \"A.jpg\")\n",
        "                label = y_test[i]\n",
        "\n",
        "                test_data.append(row)\n",
        "                test_label.append(label)\n",
        "                print(row, label)\n",
        "            except Exception as e:\n",
        "                count += 1\n",
        "                continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRx6f4o3TJGI",
        "outputId": "3acf5e40-6d8a-423a-93bc-0683b81d07b4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/IS4242/dump/labels_cnn_test.pkl']"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Dumps mediapipe test data\n",
        "joblib.dump(test_data, output_dir+'data_cnn_test.pkl')\n",
        "joblib.dump(test_label, output_dir+'labels_cnn_test.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loads mediapipe train data\n",
        "test_data = joblib.load(output_dir+'data_cnn_test.pkl')\n",
        "test_label = joblib.load(output_dir+'labels_cnn_test.pkl')"
      ],
      "metadata": {
        "id": "71n7ydDJkmYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90jo4JBIH1TW"
      },
      "outputs": [],
      "source": [
        "# Convert labels into np.array\n",
        "labels = np.array(labels)\n",
        "test_label = np.array(test_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4h6wEZv7_y4",
        "outputId": "e4d2482a-c4f5-47f6-ba08-9f15dd9621f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2754, 42, 1)\n",
            "(51, 42, 1)\n"
          ]
        }
      ],
      "source": [
        "# Convert features into np.array\n",
        "x_train = np.array(data)\n",
        "x_test = np.array(test_data)\n",
        "\n",
        "# Scale feature vectors using StandardScaler\n",
        "scaler = StandardScaler().fit(x_train)\n",
        "x_train = scaler.transform(x_train)\n",
        "x_test = scaler.transform(x_test)\n",
        "\n",
        "# Reshape feature vectors for input to Convolutional Neural Network\n",
        "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
        "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Define CNN architecture"
      ],
      "metadata": {
        "id": "fq1INTEZkKAM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define function to generate CNN model\n",
        "def CNN_model(input_shape, conv_layers) :\n",
        "  #Initalize model\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  # Add convolutional layers\n",
        "  for filters, kernel_size in conv_layers : \n",
        "    if conv_layers.index((filters, kernel_size)) == 0 :\n",
        "        model.add(tf.keras.layers.Conv1D(filters = filters, kernel_size = kernel_size, strides = 1, padding = \"same\", activation = \"relu\", input_shape = input_shape))\n",
        "    else :\n",
        "        model.add(tf.keras.layers.Conv1D(filters = filters, kernel_size = kernel_size, strides = 1, padding = \"same\", activation = \"relu\"))\n",
        "    model.add(tf.keras.layers.Conv1D(filters = filters, kernel_size = kernel_size, strides = 1, padding = \"same\", activation = \"relu\"))\n",
        "    model.add(tf.keras.layers.MaxPooling1D(pool_size = 2))\n",
        "  \n",
        "  # Add dropout layer to prevent overfitting\n",
        "  model.add(tf.keras.layers.Dropout(rate = 0.2))\n",
        "\n",
        "  # Flatten layer to 1D array\n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "  # Add dense layers for classification\n",
        "  model.add(tf.keras.layers.Dense(512, activation = \"relu\"))\n",
        "  model.add(tf.keras.layers.Dense(24, activation = \"softmax\"))\n",
        "\n",
        "  # Compile and return model\n",
        "  model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "xNNfcD2wkSEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_layers = [(32, 3), (64, 3), (128, 3)]\n",
        "model = CNN_model((42,1), conv_layers)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nCvC6XfkY_W",
        "outputId": "2774d601-51c6-4b0b-92a8-f74071b753ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_28\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_180 (Conv1D)         (None, 42, 32)            128       \n",
            "                                                                 \n",
            " conv1d_181 (Conv1D)         (None, 42, 32)            3104      \n",
            "                                                                 \n",
            " max_pooling1d_90 (MaxPoolin  (None, 21, 32)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_182 (Conv1D)         (None, 21, 64)            6208      \n",
            "                                                                 \n",
            " conv1d_183 (Conv1D)         (None, 21, 64)            12352     \n",
            "                                                                 \n",
            " max_pooling1d_91 (MaxPoolin  (None, 10, 64)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_184 (Conv1D)         (None, 10, 128)           24704     \n",
            "                                                                 \n",
            " conv1d_185 (Conv1D)         (None, 10, 128)           49280     \n",
            "                                                                 \n",
            " max_pooling1d_92 (MaxPoolin  (None, 5, 128)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " dropout_72 (Dropout)        (None, 5, 128)            0         \n",
            "                                                                 \n",
            " flatten_28 (Flatten)        (None, 640)               0         \n",
            "                                                                 \n",
            " dense_60 (Dense)            (None, 512)               328192    \n",
            "                                                                 \n",
            " dense_61 (Dense)            (None, 24)                12312     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 436,280\n",
            "Trainable params: 436,280\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cross Validation"
      ],
      "metadata": {
        "id": "ToqMnZwJk7Uq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check model performance with cross validation and do hyperparameter tuning"
      ],
      "metadata": {
        "id": "2Cv9_adwQVYN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split train test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "f2zgq8I95_M7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPniIzehk_VT",
        "outputId": "9259ecfc-6acd-4f9e-947a-db7dd340e5b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(653, 224, 224)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhgEJ63jlHzN",
        "outputId": "9db3dc77-b5f4-413d-9c6f-3f0f82c83e7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(653, 24)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define function that converts data points into mediapipe landmark points\n",
        "def convert_mediapipe(X, y) :\n",
        "    mp_drawing = mp.solutions.drawing_utils\n",
        "    mp_hands = mp.solutions.hands\n",
        "    count = 0\n",
        "    labels = []\n",
        "    data = []\n",
        "    with mp_hands.Hands(static_image_mode =True, max_num_hands = 2, min_detection_confidence=0.5) as hands:\n",
        "        for i in tqdm(range(len(X))):\n",
        "        # Load the image and extract its features\n",
        "            results = hands.process(cv2.cvtColor(cv2.flip(X[i],1), cv2.COLOR_BGR2RGB))\n",
        "            try:\n",
        "                # Extract Hand landmarks\n",
        "                for hand_landmark in results.multi_hand_landmarks:\n",
        "                    right_hand = hand_landmark.landmark\n",
        "                right_hand_row = list(np.array([[landmark.x, landmark.y] for landmark in right_hand]).flatten())\n",
        "                # Concate rows\n",
        "                row = right_hand_row\n",
        "\n",
        "                # Extract the label from the image filename (e.g. \"A.jpg\")\n",
        "                label = y[i]\n",
        "\n",
        "                data.append(row)\n",
        "                labels.append(label)\n",
        "            except Exception as e:\n",
        "                count += 1\n",
        "                continue\n",
        "    return data, labels"
      ],
      "metadata": {
        "id": "0TVCJgVMlLGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# Define function for cross validation\n",
        "def cross_validate(model, X, y, n_splits = 5) :\n",
        "    kf = StratifiedKFold(n_splits = n_splits, shuffle = True, random_state=42)\n",
        "    accuracy_scores = []\n",
        "    auc_scores_micro = []\n",
        "    f1_scores = []\n",
        "    for i, (train_index, test_index) in enumerate(kf.split(X,np.argmax(y,axis=1))):\n",
        "        print(f\"Fold {i+1}/{n_splits}:\")\n",
        "\n",
        "        # Split into train and validation sets\n",
        "        X_train, X_val = X[train_index], X[test_index]\n",
        "        y_train, y_val = y[train_index], y[test_index]\n",
        "\n",
        "        # Augment training data\n",
        "        augmented_X = []\n",
        "        augmented_y = []\n",
        "        for i in range(len(X_train)) :\n",
        "            for j in (range(10)) :\n",
        "                transformed = transform(image=X_train[i])\n",
        "                augmented_X.append(transformed['image'])\n",
        "                augmented_y.append(y_train[i])\n",
        "\n",
        "        augmented_X = np.array(augmented_X)\n",
        "        augmented_y = np.array(augmented_y)\n",
        "        X_train = np.concatenate([X_train,augmented_X])\n",
        "        y_train = np.concatenate([y_train,augmented_y])\n",
        "\n",
        "        # Convert data into mediapipe points\n",
        "        X_train, y_train = convert_mediapipe(X_train, y_train)\n",
        "        X_val, y_val = convert_mediapipe(X_val, y_val)\n",
        "        y_train = np.array(y_train)\n",
        "        y_val = np.array(y_val)\n",
        "        X_train = np.array(X_train)\n",
        "        X_val = np.array(X_val)\n",
        "        scaler = StandardScaler().fit(X_train)\n",
        "        X_train = scaler.transform(X_train)\n",
        "        X_val = scaler.transform(X_val)\n",
        "        X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
        "        X_val = np.reshape(X_val, (X_val.shape[0], X_val.shape[1], 1))\n",
        "\n",
        "        conv_layers = [(32, 3), (64, 3), (128, 3)]\n",
        "        model = CNN_model((42,1), conv_layers)\n",
        "        # Train the model on the training data\n",
        "        model.fit(X_train, y_train, epochs = 30, batch_size = 32, verbose = 0)\n",
        "\n",
        "        # Evaluate the model on the test data\n",
        "        res = model.predict(X_val)\n",
        "        y_pred = np.argmax(res, axis = 1)\n",
        "        y_t = np.argmax(y_val, axis = 1)\n",
        "        accuracy_scores.append(accuracy_score(y_t, y_pred))\n",
        "        # Use micro avg since it is sensitive to class imbalance\n",
        "        auc_scores_micro.append(roc_auc_score(y_val,res, multi_class='ovr', average='micro'))\n",
        "        f1_scores.append(f1_score(y_t, y_pred, average='weighted'))\n",
        "        print(\"ROC AUC score:\", auc_scores_micro[-1])\n",
        "        print(f\"Validation accuracy: {accuracy_scores[-1]}\")\n",
        "        print(f\"Validation F1: {f1_scores[-1]}\")\n",
        "\n",
        "    # Compute the mean accuracy and AUC ROC across all folds\n",
        "    mean_accuracy = np.mean(accuracy_scores)\n",
        "    mean_f1 = np.mean(f1_scores)\n",
        "    mean_roc_micro = np.mean(auc_scores_micro)\n",
        "    print(f\"\\nMean cross-validation accuracy: {mean_accuracy:.3f}\")\n",
        "    print(f\"\\nMean cross-validation F1: {mean_f1:.3f}\")\n",
        "    print(f\"\\nMean cross-validation AUC-ROC (micro): {mean_roc_micro:.3f}\")\n",
        "\n",
        "    return mean_accuracy, mean_roc_micro, mean_f1\n"
      ],
      "metadata": {
        "id": "QZeh7cPvlNBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_layers = [(32, 3), (64, 3), (128, 3)]\n",
        "model = CNN_model((42,1), conv_layers)\n",
        "cross_validate(model, X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYTaxRSHmTo5",
        "outputId": "c29e745e-3463-4317-ecf2-28749e79698b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1/5:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5742/5742 [04:13<00:00, 22.67it/s]\n",
            "100%|██████████| 131/131 [00:04<00:00, 27.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 123ms/step\n",
            "ROC AUC score: 0.9631233362910382\n",
            "Validation accuracy: 0.7142857142857143\n",
            "Validation F1: 0.6800680272108843\n",
            "Fold 2/5:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5742/5742 [04:01<00:00, 23.77it/s]\n",
            "100%|██████████| 131/131 [00:04<00:00, 26.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step\n",
            "ROC AUC score: 0.981625258799172\n",
            "Validation accuracy: 0.8095238095238095\n",
            "Validation F1: 0.7913832199546486\n",
            "Fold 3/5:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5742/5742 [04:05<00:00, 23.43it/s]\n",
            "100%|██████████| 131/131 [00:04<00:00, 26.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step\n",
            "ROC AUC score: 0.9720404521118382\n",
            "Validation accuracy: 0.6341463414634146\n",
            "Validation F1: 0.6146341463414634\n",
            "Fold 4/5:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5753/5753 [04:02<00:00, 23.70it/s]\n",
            "100%|██████████| 130/130 [00:05<00:00, 21.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 1s 6ms/step\n",
            "ROC AUC score: 0.9621311744883702\n",
            "Validation accuracy: 0.717391304347826\n",
            "Validation F1: 0.7185300207039339\n",
            "Fold 5/5:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5753/5753 [04:00<00:00, 23.96it/s]\n",
            "100%|██████████| 130/130 [00:05<00:00, 25.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step\n",
            "ROC AUC score: 0.9463708228530364\n",
            "Validation accuracy: 0.6590909090909091\n",
            "Validation F1: 0.6598484848484849\n",
            "\n",
            "Mean cross-validation accuracy: 0.707\n",
            "\n",
            "Mean cross-validation F1: 0.693\n",
            "\n",
            "Mean cross-validation AUC-ROC (micro): 0.965\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7068876157423347, 0.965058208908691, 0.6928927798118831)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxyNN788QorR"
      },
      "source": [
        "#### Check performance with test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LwboURpt6WxN"
      },
      "outputs": [],
      "source": [
        "# Set a learning rate annealer\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n",
        "                                            patience=3, \n",
        "                                            verbose=1, \n",
        "                                            factor=0.5, \n",
        "                                            min_lr=0.00001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9TQ5vv56WxO",
        "outputId": "e912294c-997a-46d8-9387-9925577f1ab1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "84/86 [============================>.] - ETA: 0s - loss: 2.2775 - accuracy: 0.3352\n",
            "Epoch 1: val_accuracy improved from -inf to 0.45098, saving model to best.h5\n",
            "86/86 [==============================] - 6s 16ms/step - loss: 2.2478 - accuracy: 0.3438 - val_loss: 1.6679 - val_accuracy: 0.4510 - lr: 0.0010\n",
            "Epoch 2/30\n",
            "85/86 [============================>.] - ETA: 0s - loss: 0.6365 - accuracy: 0.8119\n",
            "Epoch 2: val_accuracy improved from 0.45098 to 0.68627, saving model to best.h5\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.6329 - accuracy: 0.8130 - val_loss: 1.3629 - val_accuracy: 0.6863 - lr: 0.0010\n",
            "Epoch 3/30\n",
            "78/86 [==========================>...] - ETA: 0s - loss: 0.2847 - accuracy: 0.9120\n",
            "Epoch 3: val_accuracy did not improve from 0.68627\n",
            "86/86 [==============================] - 1s 6ms/step - loss: 0.2788 - accuracy: 0.9126 - val_loss: 1.2911 - val_accuracy: 0.6863 - lr: 0.0010\n",
            "Epoch 4/30\n",
            "79/86 [==========================>...] - ETA: 0s - loss: 0.1638 - accuracy: 0.9528\n",
            "Epoch 4: val_accuracy improved from 0.68627 to 0.74510, saving model to best.h5\n",
            "86/86 [==============================] - 1s 6ms/step - loss: 0.1609 - accuracy: 0.9530 - val_loss: 1.3062 - val_accuracy: 0.7451 - lr: 0.0010\n",
            "Epoch 5/30\n",
            "86/86 [==============================] - ETA: 0s - loss: 0.1027 - accuracy: 0.9713\n",
            "Epoch 5: val_accuracy improved from 0.74510 to 0.76471, saving model to best.h5\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.1027 - accuracy: 0.9713 - val_loss: 1.5896 - val_accuracy: 0.7647 - lr: 0.0010\n",
            "Epoch 6/30\n",
            "80/86 [==========================>...] - ETA: 0s - loss: 0.0790 - accuracy: 0.9751\n",
            "Epoch 6: val_accuracy did not improve from 0.76471\n",
            "86/86 [==============================] - 1s 6ms/step - loss: 0.0811 - accuracy: 0.9735 - val_loss: 1.2584 - val_accuracy: 0.7255 - lr: 0.0010\n",
            "Epoch 7/30\n",
            "79/86 [==========================>...] - ETA: 0s - loss: 0.0752 - accuracy: 0.9776\n",
            "Epoch 7: val_accuracy did not improve from 0.76471\n",
            "86/86 [==============================] - 0s 6ms/step - loss: 0.0717 - accuracy: 0.9783 - val_loss: 1.9832 - val_accuracy: 0.7255 - lr: 0.0010\n",
            "Epoch 8/30\n",
            "79/86 [==========================>...] - ETA: 0s - loss: 0.0331 - accuracy: 0.9916\n",
            "Epoch 8: val_accuracy did not improve from 0.76471\n",
            "\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "86/86 [==============================] - 1s 6ms/step - loss: 0.0323 - accuracy: 0.9916 - val_loss: 1.9457 - val_accuracy: 0.7255 - lr: 0.0010\n",
            "Epoch 9/30\n",
            "86/86 [==============================] - ETA: 0s - loss: 0.0183 - accuracy: 0.9960\n",
            "Epoch 9: val_accuracy did not improve from 0.76471\n",
            "86/86 [==============================] - 1s 6ms/step - loss: 0.0183 - accuracy: 0.9960 - val_loss: 1.6140 - val_accuracy: 0.7451 - lr: 5.0000e-04\n",
            "Epoch 10/30\n",
            "80/86 [==========================>...] - ETA: 0s - loss: 0.0148 - accuracy: 0.9968\n",
            "Epoch 10: val_accuracy did not improve from 0.76471\n",
            "86/86 [==============================] - 0s 6ms/step - loss: 0.0142 - accuracy: 0.9971 - val_loss: 1.4393 - val_accuracy: 0.7255 - lr: 5.0000e-04\n",
            "Epoch 11/30\n",
            "81/86 [===========================>..] - ETA: 0s - loss: 0.0060 - accuracy: 0.9980\n",
            "Epoch 11: val_accuracy did not improve from 0.76471\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "86/86 [==============================] - 1s 6ms/step - loss: 0.0067 - accuracy: 0.9978 - val_loss: 1.7881 - val_accuracy: 0.7451 - lr: 5.0000e-04\n",
            "Epoch 12/30\n",
            "78/86 [==========================>...] - ETA: 0s - loss: 0.0031 - accuracy: 0.9996\n",
            "Epoch 12: val_accuracy did not improve from 0.76471\n",
            "86/86 [==============================] - 1s 6ms/step - loss: 0.0031 - accuracy: 0.9996 - val_loss: 1.7752 - val_accuracy: 0.7451 - lr: 2.5000e-04\n",
            "Epoch 13/30\n",
            "83/86 [===========================>..] - ETA: 0s - loss: 0.0026 - accuracy: 0.9996\n",
            "Epoch 13: val_accuracy did not improve from 0.76471\n",
            "86/86 [==============================] - 1s 6ms/step - loss: 0.0026 - accuracy: 0.9996 - val_loss: 1.7614 - val_accuracy: 0.7255 - lr: 2.5000e-04\n",
            "Epoch 14/30\n",
            "86/86 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 0.9996\n",
            "Epoch 14: val_accuracy did not improve from 0.76471\n",
            "\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "86/86 [==============================] - 1s 6ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 1.8033 - val_accuracy: 0.7647 - lr: 2.5000e-04\n",
            "Epoch 15/30\n",
            "79/86 [==========================>...] - ETA: 0s - loss: 0.0015 - accuracy: 0.9996\n",
            "Epoch 15: val_accuracy did not improve from 0.76471\n",
            "86/86 [==============================] - 0s 6ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 1.8715 - val_accuracy: 0.7647 - lr: 1.2500e-04\n",
            "Epoch 16/30\n",
            "85/86 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 16: val_accuracy did not improve from 0.76471\n",
            "86/86 [==============================] - 1s 6ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.8955 - val_accuracy: 0.7451 - lr: 1.2500e-04\n",
            "Epoch 17/30\n",
            "85/86 [============================>.] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 17: val_accuracy did not improve from 0.76471\n",
            "\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "86/86 [==============================] - 1s 6ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.9186 - val_accuracy: 0.7647 - lr: 1.2500e-04\n",
            "Epoch 18/30\n",
            "80/86 [==========================>...] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 18: val_accuracy did not improve from 0.76471\n",
            "86/86 [==============================] - 1s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.9176 - val_accuracy: 0.7647 - lr: 6.2500e-05\n",
            "Epoch 19/30\n",
            "78/86 [==========================>...] - ETA: 0s - loss: 6.7956e-04 - accuracy: 1.0000\n",
            "Epoch 19: val_accuracy did not improve from 0.76471\n",
            "86/86 [==============================] - 1s 6ms/step - loss: 7.9619e-04 - accuracy: 1.0000 - val_loss: 1.9291 - val_accuracy: 0.7647 - lr: 6.2500e-05\n",
            "Epoch 20/30\n",
            "81/86 [===========================>..] - ETA: 0s - loss: 0.0014 - accuracy: 0.9996\n",
            "Epoch 20: val_accuracy did not improve from 0.76471\n",
            "\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "86/86 [==============================] - 1s 9ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 1.9550 - val_accuracy: 0.7451 - lr: 6.2500e-05\n",
            "Epoch 21/30\n",
            "80/86 [==========================>...] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000    \n",
            "Epoch 21: val_accuracy did not improve from 0.76471\n",
            "86/86 [==============================] - 1s 8ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.9425 - val_accuracy: 0.7451 - lr: 3.1250e-05\n",
            "Epoch 22/30\n",
            "83/86 [===========================>..] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 22: val_accuracy did not improve from 0.76471\n",
            "86/86 [==============================] - 1s 8ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.9443 - val_accuracy: 0.7647 - lr: 3.1250e-05\n",
            "Epoch 23/30\n",
            "84/86 [============================>.] - ETA: 0s - loss: 8.4198e-04 - accuracy: 1.0000\n",
            "Epoch 23: val_accuracy did not improve from 0.76471\n",
            "\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "86/86 [==============================] - 1s 8ms/step - loss: 8.3162e-04 - accuracy: 1.0000 - val_loss: 1.9469 - val_accuracy: 0.7647 - lr: 3.1250e-05\n",
            "Epoch 24/30\n",
            "83/86 [===========================>..] - ETA: 0s - loss: 8.3591e-04 - accuracy: 1.0000\n",
            "Epoch 24: val_accuracy did not improve from 0.76471\n",
            "86/86 [==============================] - 1s 8ms/step - loss: 8.8470e-04 - accuracy: 1.0000 - val_loss: 1.9469 - val_accuracy: 0.7647 - lr: 1.5625e-05\n",
            "Epoch 25/30\n",
            "83/86 [===========================>..] - ETA: 0s - loss: 7.1154e-04 - accuracy: 1.0000\n",
            "Epoch 25: val_accuracy did not improve from 0.76471\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 6.9490e-04 - accuracy: 1.0000 - val_loss: 1.9502 - val_accuracy: 0.7647 - lr: 1.5625e-05\n",
            "Epoch 26/30\n",
            "85/86 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 26: val_accuracy did not improve from 0.76471\n",
            "\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "86/86 [==============================] - 1s 6ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.9431 - val_accuracy: 0.7647 - lr: 1.5625e-05\n",
            "Epoch 26: early stopping\n"
          ]
        }
      ],
      "source": [
        "epochs = 30\n",
        "batch_size = 32\n",
        "\n",
        "conv_layers = [(32, 3), (64, 3), (128, 3)]\n",
        "model = CNN_model((42,1), conv_layers)\n",
        "model_checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=\"best.h5\",\n",
        "    monitor='val_accuracy', \n",
        "    verbose=1, \n",
        "    save_best_only=True, \n",
        "    mode='max')\n",
        "\n",
        "es = EarlyStopping(monitor=\"val_loss\", mode=\"min\", verbose=1, patience=20)\n",
        "\n",
        "model = CNN_model(x_train.shape[1:3], conv_layers)\n",
        "# Fit the model\n",
        "history = model.fit(x_train, labels, batch_size=batch_size,\n",
        "                              epochs = epochs, validation_data = (x_test, test_label),steps_per_epoch=x_train.shape[0] // batch_size,\n",
        "                              verbose = 1,   callbacks=[model_checkpoint_callback,learning_rate_reduction,es])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ep7lwwcQvNJ"
      },
      "source": [
        "#### Prediction and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "851d8Xy0Npz7",
        "outputId": "2d465296-caee-45eb-8495-e412da5afde8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 8ms/step\n"
          ]
        }
      ],
      "source": [
        "results = model.predict(x_test)\n",
        "y_pred = np.argmax(results,axis = 1) \n",
        "y_true = np.argmax(test_label,axis = 1) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQxI5oj3Npz8",
        "outputId": "5fcec535-d0aa-4ef1-a3b0-8f70637d7150"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.33      0.50         3\n",
            "           1       1.00      1.00      1.00         3\n",
            "           2       0.00      0.00      0.00         2\n",
            "           3       1.00      0.50      0.67         2\n",
            "           4       1.00      1.00      1.00         2\n",
            "           5       1.00      1.00      1.00         2\n",
            "           6       1.00      1.00      1.00         3\n",
            "           7       1.00      1.00      1.00         2\n",
            "           8       1.00      1.00      1.00         2\n",
            "           9       0.50      1.00      0.67         2\n",
            "          10       1.00      1.00      1.00         3\n",
            "          11       0.00      0.00      0.00         1\n",
            "          12       0.50      1.00      0.67         1\n",
            "          13       0.50      1.00      0.67         1\n",
            "          14       0.67      1.00      0.80         2\n",
            "          15       1.00      1.00      1.00         2\n",
            "          16       0.67      1.00      0.80         2\n",
            "          17       0.00      0.00      0.00         2\n",
            "          18       0.33      0.33      0.33         3\n",
            "          19       1.00      1.00      1.00         1\n",
            "          20       1.00      0.50      0.67         2\n",
            "          21       1.00      1.00      1.00         1\n",
            "          22       0.75      0.75      0.75         4\n",
            "          23       0.60      1.00      0.75         3\n",
            "\n",
            "    accuracy                           0.76        51\n",
            "   macro avg       0.73      0.77      0.72        51\n",
            "weighted avg       0.75      0.76      0.73        51\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_true, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMspzzLqNwKe",
        "outputId": "2e89f8dc-c2f9-4a33-d226-a850aea268e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC AUC score (micro average): 0.9835681928355315\n",
            "ROC AUC score (macro average): 0.9788832752368086\n"
          ]
        }
      ],
      "source": [
        "roc_auc = roc_auc_score(test_label, results, multi_class='ovr', average='micro')\n",
        "print(\"ROC AUC score (micro average):\", roc_auc)\n",
        "roc_auc = roc_auc_score(test_label, results, multi_class='ovr', average='macro')\n",
        "print(\"ROC AUC score (macro average):\", roc_auc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L09e6FY2aF3Q"
      },
      "source": [
        "### Train on whole dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DdFuOOppOVO9"
      },
      "outputs": [],
      "source": [
        "# Initialize list for augmented data\n",
        "augmented_X = []\n",
        "augmented_y = []\n",
        "\n",
        "# Iterates through data\n",
        "for i in range(len(X)):\n",
        "\n",
        "  # Generate 10 iterations of augmented data and store in list\n",
        "  for j in (range(10)):\n",
        "      transformed = transform(image=X[i])\n",
        "      augmented_X.append(transformed['image'])\n",
        "      augmented_y.append(y[i])\n",
        "\n",
        "# Convert augmented data into np.array and concatenate with original dataset\n",
        "augmented_X = np.array(augmented_X)\n",
        "augmented_y = np.array(augmented_y)\n",
        "X = np.concatenate([X,augmented_X])\n",
        "y = np.concatenate([y,augmented_y])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYZk0RV_b-DR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6733f0dc-1b22-4624-dd49-fa4566d53db2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8987/8987 [06:38<00:00, 22.58it/s]\n"
          ]
        }
      ],
      "source": [
        "# Convert points using mediapipe\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_hands = mp.solutions.hands\n",
        "data = []\n",
        "labels = []\n",
        "count = 0\n",
        "with mp_hands.Hands(static_image_mode =True, max_num_hands = 2, min_detection_confidence=0.5) as hands:\n",
        "    for i in tqdm(range(len(X))):\n",
        "        # Load the image and extract its features\n",
        "            results = hands.process(cv2.cvtColor(cv2.flip(X[i],1), cv2.COLOR_BGR2RGB))\n",
        "            try:\n",
        "                # Extract Hand landmarks\n",
        "                for hand_landmark in results.multi_hand_landmarks:\n",
        "                    right_hand = hand_landmark.landmark\n",
        "                right_hand_row = list(np.array([[landmark.x, landmark.y] for landmark in right_hand]).flatten())\n",
        "                # Concate rows\n",
        "                row = right_hand_row\n",
        "\n",
        "                # Extract the label from the image filename (e.g. \"A.jpg\")\n",
        "                label = y[i]\n",
        "\n",
        "                data.append(row)\n",
        "                labels.append(label)\n",
        "            except Exception as e:\n",
        "                count += 1\n",
        "                continue\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dump complete datsaset with augmentation\n",
        "joblib.dump(data, output_dir+'data_cnn_full.pkl')\n",
        "joblib.dump(labels, output_dir+'labels_cnn_full.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoxweBzLRV3Q",
        "outputId": "2d82d787-0c6d-4c36-8472-88a62848b3bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/IS4242/dump/labels_cnn_full.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQOvF67ecbmD"
      },
      "outputs": [],
      "source": [
        "# Loads complete datsaset with augmentation\n",
        "data = joblib.load(output_dir+'data_cnn_full.pkl')\n",
        "labels = joblib.load(output_dir+'labels_cnn_full.pkl')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jz8r7vLicRpW"
      },
      "outputs": [],
      "source": [
        "# Convert labels and features as np.array\n",
        "labels = np.array(labels)\n",
        "data = np.array(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Zj1_VnbcRp6",
        "outputId": "8f3069e2-194b-4cdb-aa35-28a32178925f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2946, 42, 1)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "# Scales the features using StandardScaler\n",
        "scaler = StandardScaler().fit(data)\n",
        "x = scaler.transform(data)\n",
        "x = np.reshape(x, (x.shape[0], x.shape[1], 1))\n",
        "print(x.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IsKXDo0DcRp7",
        "outputId": "15cb0c4d-3882-4924-c106-c58ecf296a5e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2946, 24)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "labels.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2luZcUlcRp8"
      },
      "source": [
        "#### CNN Architecture with augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3-iDVK-cRp9",
        "outputId": "7b1627d8-e183-4342-fde8-e6eb5ebdd337"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_25\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_135 (Conv1D)         (None, 42, 32)            128       \n",
            "                                                                 \n",
            " conv1d_136 (Conv1D)         (None, 42, 32)            3104      \n",
            "                                                                 \n",
            " max_pooling1d_102 (MaxPooli  (None, 21, 32)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_137 (Conv1D)         (None, 21, 64)            6208      \n",
            "                                                                 \n",
            " conv1d_138 (Conv1D)         (None, 21, 64)            12352     \n",
            "                                                                 \n",
            " max_pooling1d_103 (MaxPooli  (None, 10, 64)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_139 (Conv1D)         (None, 10, 128)           24704     \n",
            "                                                                 \n",
            " conv1d_140 (Conv1D)         (None, 10, 128)           49280     \n",
            "                                                                 \n",
            " max_pooling1d_104 (MaxPooli  (None, 5, 128)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dropout_25 (Dropout)        (None, 5, 128)            0         \n",
            "                                                                 \n",
            " flatten_25 (Flatten)        (None, 640)               0         \n",
            "                                                                 \n",
            " dense_50 (Dense)            (None, 512)               328192    \n",
            "                                                                 \n",
            " dense_51 (Dense)            (None, 24)                12312     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 436,280\n",
            "Trainable params: 436,280\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Construct CNN model\n",
        "conv_layers = [(32, 3), (64, 3), (128, 3)]\n",
        "model = CNN_model((42,1), conv_layers)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QujxejzAcRp-",
        "outputId": "a8eb5471-876b-4388-baeb-1b1e2fda770b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "92/92 [==============================] - 3s 6ms/step - loss: 2.3743 - accuracy: 0.3234\n",
            "Epoch 2/30\n",
            "92/92 [==============================] - 1s 6ms/step - loss: 0.9208 - accuracy: 0.7378\n",
            "Epoch 3/30\n",
            "92/92 [==============================] - 1s 6ms/step - loss: 0.5663 - accuracy: 0.8487\n",
            "Epoch 4/30\n",
            "92/92 [==============================] - 1s 6ms/step - loss: 0.3943 - accuracy: 0.8974\n",
            "Epoch 5/30\n",
            "92/92 [==============================] - 1s 6ms/step - loss: 0.3103 - accuracy: 0.9091\n",
            "Epoch 6/30\n",
            "92/92 [==============================] - 1s 7ms/step - loss: 0.2073 - accuracy: 0.9379\n",
            "Epoch 7/30\n",
            "92/92 [==============================] - 1s 7ms/step - loss: 0.2766 - accuracy: 0.9204\n",
            "Epoch 8/30\n",
            "92/92 [==============================] - 1s 8ms/step - loss: 0.1515 - accuracy: 0.9612\n",
            "Epoch 9/30\n",
            "92/92 [==============================] - 1s 7ms/step - loss: 0.1566 - accuracy: 0.9537\n",
            "Epoch 10/30\n",
            "92/92 [==============================] - 1s 8ms/step - loss: 0.0933 - accuracy: 0.9732\n",
            "Epoch 11/30\n",
            "92/92 [==============================] - 1s 8ms/step - loss: 0.0773 - accuracy: 0.9794\n",
            "Epoch 12/30\n",
            "92/92 [==============================] - 1s 6ms/step - loss: 0.1428 - accuracy: 0.9581\n",
            "Epoch 13/30\n",
            "92/92 [==============================] - 1s 6ms/step - loss: 0.0881 - accuracy: 0.9701\n",
            "Epoch 14/30\n",
            "92/92 [==============================] - 1s 6ms/step - loss: 0.0609 - accuracy: 0.9835\n",
            "Epoch 15/30\n",
            "92/92 [==============================] - 1s 6ms/step - loss: 0.0527 - accuracy: 0.9866\n",
            "Epoch 16/30\n",
            "92/92 [==============================] - 1s 6ms/step - loss: 0.0351 - accuracy: 0.9904\n",
            "Epoch 17/30\n",
            "92/92 [==============================] - 1s 6ms/step - loss: 0.0346 - accuracy: 0.9904\n",
            "Epoch 18/30\n",
            "92/92 [==============================] - 1s 6ms/step - loss: 0.0419 - accuracy: 0.9873\n",
            "Epoch 19/30\n",
            "92/92 [==============================] - 1s 6ms/step - loss: 0.0700 - accuracy: 0.9815\n",
            "Epoch 20/30\n",
            "92/92 [==============================] - 1s 6ms/step - loss: 0.0416 - accuracy: 0.9866\n",
            "Epoch 21/30\n",
            "92/92 [==============================] - 1s 6ms/step - loss: 0.0497 - accuracy: 0.9842\n",
            "Epoch 22/30\n",
            "92/92 [==============================] - 1s 6ms/step - loss: 0.0947 - accuracy: 0.9715\n",
            "Epoch 23/30\n",
            "92/92 [==============================] - 1s 6ms/step - loss: 0.0569 - accuracy: 0.9835\n",
            "Epoch 24/30\n",
            "92/92 [==============================] - 1s 6ms/step - loss: 0.0437 - accuracy: 0.9883\n",
            "Epoch 25/30\n",
            "92/92 [==============================] - 1s 6ms/step - loss: 0.1959 - accuracy: 0.9492\n",
            "Epoch 26/30\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.0302 - accuracy: 0.9904\n",
            "Epoch 27/30\n",
            "92/92 [==============================] - 1s 6ms/step - loss: 0.0290 - accuracy: 0.9935\n",
            "Epoch 28/30\n",
            "92/92 [==============================] - 1s 5ms/step - loss: 0.0341 - accuracy: 0.9880\n",
            "Epoch 29/30\n",
            "92/92 [==============================] - 1s 6ms/step - loss: 0.0407 - accuracy: 0.9890\n",
            "Epoch 30/30\n",
            "92/92 [==============================] - 1s 6ms/step - loss: 0.0365 - accuracy: 0.9894\n"
          ]
        }
      ],
      "source": [
        "epochs = 30\n",
        "batch_size = 32\n",
        "\n",
        "# Fit the model\n",
        "history = model.fit(x, labels, batch_size=batch_size,\n",
        "                              epochs = epochs,steps_per_epoch=x.shape[0] // batch_size,\n",
        "                              verbose = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okn46X5Df64a"
      },
      "outputs": [],
      "source": [
        "model.save('cnn.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7FYBgaJcRp_"
      },
      "source": [
        "#### Prediction and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twVVS2vjcRqA",
        "outputId": "704978d3-a01c-4b03-893e-44988952b887"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "93/93 [==============================] - 0s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "results = model.predict(x)\n",
        "y_pred = np.argmax(results,axis = 1) \n",
        "y_true = np.argmax(labels,axis = 1) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCR0GFTdcRqB",
        "outputId": "5caf7324-7ffc-4ecc-9820-a1c4866a069b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       134\n",
            "           1       0.99      1.00      1.00       127\n",
            "           2       1.00      0.99      0.99       139\n",
            "           3       1.00      0.97      0.99       111\n",
            "           4       1.00      0.99      1.00       134\n",
            "           5       1.00      1.00      1.00       138\n",
            "           6       1.00      1.00      1.00       142\n",
            "           7       1.00      1.00      1.00       129\n",
            "           8       1.00      0.99      1.00       103\n",
            "           9       1.00      1.00      1.00       113\n",
            "          10       1.00      0.99      1.00       126\n",
            "          11       0.98      1.00      0.99        96\n",
            "          12       1.00      0.99      0.99        98\n",
            "          13       0.98      1.00      0.99        93\n",
            "          14       1.00      1.00      1.00       130\n",
            "          15       0.99      1.00      1.00       103\n",
            "          16       1.00      0.99      1.00       109\n",
            "          17       1.00      0.99      1.00       103\n",
            "          18       0.99      0.99      0.99       148\n",
            "          19       1.00      1.00      1.00        89\n",
            "          20       0.98      1.00      0.99       115\n",
            "          21       1.00      1.00      1.00        90\n",
            "          22       0.98      1.00      0.99       214\n",
            "          23       1.00      0.99      0.99       162\n",
            "\n",
            "    accuracy                           1.00      2946\n",
            "   macro avg       1.00      1.00      1.00      2946\n",
            "weighted avg       1.00      1.00      1.00      2946\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_true, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOea00HXcRqC",
        "outputId": "5d68d8a3-ecec-40f4-ba1e-9a28903fbf23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC AUC score: 0.9999623475318006\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "import numpy as np\n",
        "\n",
        "# Calculate the ROC AUC using the micro-averaging method\n",
        "roc_auc = roc_auc_score(labels, results, multi_class='ovo', average='micro')\n",
        "print(\"ROC AUC score:\", roc_auc)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}